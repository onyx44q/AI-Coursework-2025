{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47586c2f",
   "metadata": {},
   "source": [
    "Exploratory analysis:\n",
    "# Styling plot\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "#  Relationship between Carat (weight) and Price\n",
    "\n",
    "# Let's explore how a diamond's weight (carat) influences its price.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='carat', y='price', data=diamonds_df, alpha=0.1)\n",
    "plt.title('Price vs. Carat')\n",
    "plt.xlabel('Carat')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Observation 1: Effect of Cut Quality on Price\n",
    "\n",
    "# Now, let’s examine how the quality of the cut impacts the price.\n",
    "# We’ll use a boxplot to compare price distributions across different cut grades.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    x='cut',\n",
    "    y='price',\n",
    "    data=diamonds_df,\n",
    "    order=['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']  # Order by increasing quality\n",
    ")\n",
    "plt.title('Price Distribution by Cut Quality')\n",
    "plt.xlabel('Cut Quality')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Observation 2: Correlation Between Numeric Features\n",
    "\n",
    "# Next, let’s look at how all the numeric attributes relate to each other.\n",
    "# We’ll calculate and visualize the correlation matrix using a heatmap.\n",
    "plt.figure(figsize=(10, 7))\n",
    "corr_matrix = diamonds_df.corr(numeric_only=True)\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Observation 3:\n",
    "\n",
    "# The price of a diamond is very strongly linked to its carat weight (correlation of 0.92)\n",
    "# and its physical dimensions (x, y, z). Carat and the dimensions are also almost perfectly\n",
    "# correlated with each other — which makes sense, since heavier diamonds tend to be larger.\n",
    "# In contrast, features like depth and table have only a weak connection to price.\n",
    "\n",
    "\n",
    "# Step 2: Create a Sample Dataset for Modeling\n",
    "\n",
    "# Finally, we’ll create a smaller random sample from the original dataset\n",
    "# to make modeling and experimentation faster. Using a random_state ensures reproducibility.\n",
    "diamonds_model = diamonds_df.sample(n=12500, random_state=42)\n",
    "print(f\"\\nCreated 'diamonds_model' sample with shape: {diamonds_model.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6fb54",
   "metadata": {},
   "source": [
    "Linear regression:\n",
    "\n",
    "\n",
    "# Step 1: Define the Proper Order of Categorical Features\n",
    "\n",
    "# We’ll specify the natural order of quality for each categorical variable.\n",
    "# This ensures our encoding reflects the true ranking of quality levels.\n",
    "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
    "color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
    "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "\n",
    "\n",
    "# Step 2: Create a Copy for Modeling\n",
    "\n",
    "# To keep our original sample intact, we’ll work on a copy.\n",
    "df_model1 = diamonds_model.copy()\n",
    "\n",
    "\n",
    "# Step 3: Encode Categorical Features into Numeric Form\n",
    "# Since machine learning models require numeric input, we’ll use an OrdinalEncoder\n",
    "# that assigns integer values based on the defined order above.\n",
    "encoder = OrdinalEncoder(categories=[cut_order, color_order, clarity_order], dtype=int)\n",
    "df_model1[['cut', 'color', 'clarity']] = encoder.fit_transform(df_model1[['cut', 'color', 'clarity']])\n",
    "\n",
    "print(\"\\nData after Ordinal Encoding (first 5 rows):\")\n",
    "print(df_model1.head())\n",
    "\n",
    "\n",
    "# Step 4: Define Features (X) and Target (y)\n",
    "\n",
    "# Our goal is to predict diamond price, so it will serve as the target variable (y).\n",
    "# The remaining columns are our predictors (X).\n",
    "X = df_model1.drop('price', axis=1)\n",
    "y = df_model1['price']\n",
    "\n",
    "\n",
    "# Step 5: Split the Data into Training and Test Sets\n",
    "\n",
    "# We’ll use an 80/20 split to train the model on most of the data\n",
    "# and evaluate its performance on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Step 6: Standardize the Features\n",
    "# Scaling helps ensure all numeric features contribute equally to the model.\n",
    "# We’ll apply standard scaling (mean = 0, std = 1) to both training and test sets.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 7: Train a Linear Regression Model\n",
    "# We’ll start with a simple Linear Regression model to understand\n",
    "# how well the numeric and encoded features can explain diamond prices.\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Step 8: Evaluate Model Performance\n",
    "# Using the trained model, we’ll make predictions on the test set\n",
    "# and calculate two key metrics:\n",
    "# - R²: how much of the price variation the model explains\n",
    "# - RMSE: the average prediction error in the same units as price\n",
    "y_pred_lr = model_lr.predict(X_test_scaled)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\n--- Model 1: Full Linear Regression Results ---\")\n",
    "print(f\"R-squared (R²): {r2_lr:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lr:.2f}\")\n",
    "\n",
    "\n",
    "# Step 9: Store Results for Future Comparison\n",
    "# We’ll save the model’s performance scores to compare with future models.\n",
    "model_scores = {\n",
    "    'Full Linear Regression': {'R²': r2_lr, 'RMSE': rmse_lr}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ff7e1",
   "metadata": {},
   "source": [
    "PCA, Lasso and Ridge:\n",
    "\n",
    "\n",
    "# Step 1: Select Only Continuous (Numeric) Features\n",
    "# For PCA, we’ll focus on the continuous numerical features that describe\n",
    "# a diamond’s physical properties — these are the ones most suitable for\n",
    "# dimensionality reduction.\n",
    "continuous_features = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "y_pca = diamonds_model['price']  # The target remains the same\n",
    "X_continuous = diamonds_model[continuous_features]\n",
    "\n",
    "\n",
    "# Step 2: Standardize the Data\n",
    "# PCA is very sensitive to feature scale, so we standardize the data first.\n",
    "# This ensures that each feature contributes equally to the analysis.\n",
    "scaler_pca = StandardScaler()\n",
    "X_continuous_scaled = scaler_pca.fit_transform(X_continuous)\n",
    "\n",
    "\n",
    "# Step 3: Apply PCA (Principal Component Analysis)\n",
    "# We’ll reduce the dataset to 2 principal components — these capture\n",
    "# the most important patterns and structure in the data while minimizing\n",
    "# information loss.\n",
    "pca = PCA(n_components=2)\n",
    "X_pca_components = pca.fit_transform(X_continuous_scaled)\n",
    "\n",
    "print(f\"\\nExplained variance by 2 PCA components: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "# This value shows how much of the total variance (information) \n",
    "# the first two components managed to preserve.\n",
    "\n",
    "\n",
    "# Step 4: Train/Test Split for the PCA Components\n",
    "# We’ll split the reduced data into training and testing sets, just like before.\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
    "    X_pca_components, y_pca, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Step 5: Train a Linear Regression Model on PCA Data\n",
    "# Now, we train a simple Linear Regression model using the 2 PCA components.\n",
    "# This helps us see how well a lower-dimensional representation performs.\n",
    "model_pca_lr = LinearRegression()\n",
    "model_pca_lr.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "\n",
    "# Step 6: Evaluate PCA Model Performance\n",
    "y_pred_pca = model_pca_lr.predict(X_test_pca)\n",
    "r2_pca = r2_score(y_test_pca, y_pred_pca)\n",
    "rmse_pca = np.sqrt(mean_squared_error(y_test_pca, y_pred_pca))\n",
    "\n",
    "print(\"\\n--- Model 2: PCA (2 Components) Linear Regression Results ---\")\n",
    "print(f\"R-squared (R²): {r2_pca:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_pca:.2f}\")\n",
    "\n",
    "# Save results for later comparison\n",
    "model_scores['PCA Regression'] = {'R²': r2_pca, 'RMSE': rmse_pca}\n",
    "\n",
    "# Step 7: Lasso Regression (L1 Regularization)\n",
    "# Lasso helps by shrinking less important feature coefficients to zero,\n",
    "# effectively performing feature selection while controlling overfitting.\n",
    "model_lasso = Lasso(alpha=1.0, random_state=42)  # alpha controls the penalty strength\n",
    "model_lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the Lasso model\n",
    "y_pred_lasso = model_lasso.predict(X_test_scaled)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "\n",
    "print(\"\\n--- Model 3: Lasso Regression Results ---\")\n",
    "print(f\"R-squared (R²): {r2_lasso:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso:.2f}\")\n",
    "\n",
    "model_scores['Lasso Regression'] = {'R²': r2_lasso, 'RMSE': rmse_lasso}\n",
    "\n",
    "\n",
    "\n",
    "# Step 8: Ridge Regression (L2 Regularization)\n",
    "# Ridge regression works similarly to Lasso but shrinks coefficients\n",
    "# without setting them exactly to zero — good for handling multicollinearity.\n",
    "model_ridge = Ridge(alpha=1.0, random_state=42)\n",
    "model_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the Ridge model\n",
    "y_pred_ridge = model_ridge.predict(X_test_scaled)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "\n",
    "print(\"\\n--- Model 4: Ridge Regression Results ---\")\n",
    "print(f\"R-squared (R²): {r2_ridge:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_ridge:.2f}\")\n",
    "\n",
    "model_scores['Ridge Regression'] = {'R²': r2_ridge, 'RMSE': rmse_ridge}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357bdc0",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "\n",
    "# Put the scores into a nice DataFrame for comparison\n",
    "scores_df = pd.DataFrame(model_scores).T\n",
    "scores_df = scores_df.sort_values(by='R²', ascending=False)\n",
    "\n",
    "print(\"\\n--- Final Model Comparison ---\")\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a38e4",
   "metadata": {},
   "source": [
    "Which model had the highest accuracy?\n",
    "\n",
    "The Full Linear Regression model (along with its close variants, Ridge and Lasso) achieved the best accuracy overall. Among them, Ridge Regression performed slightly better, reaching an R² of 0.9205. The standard Linear Regression and Lasso Regression models were almost identical in performance, showing only minor differences.\n",
    "In contrast, the PCA Regression model performed noticeably worse, with an R² of just 0.8526 — a clear drop in accuracy.\n",
    "\n",
    "Why did this happen?\n",
    "\n",
    "Full Model (Winner):\n",
    "The full models — Linear, Ridge, and Lasso — performed best because they had access to all the relevant features of the dataset. These models used carat, depth, table, all three physical dimensions (x, y, z), and the quality attributes: cut, color, and clarity.\n",
    "Having this complete set of information gave the models a much richer understanding of what drives diamond prices. The small improvement seen in Ridge and Lasso suggests that the plain Linear model may have had a touch of overfitting, which the regularization techniques (Ridge/Lasso) helped to smooth out.\n",
    "\n",
    "PCA Model (Loser):\n",
    "The PCA-based model struggled because we intentionally limited its knowledge. It was trained using only two principal components derived from six continuous features, and it did not include the categorical features like cut, color, or clarity — which are critical factors in determining price.\n",
    "In other words, the PCA model was trying to predict diamond prices with most of the key information missing, which naturally led to weaker performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
