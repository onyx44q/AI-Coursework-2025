{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13e5580",
   "metadata": {},
   "source": [
    "Features and Accuracy\n",
    "# NEW SECTION: Feature Selection (Before Modeling)\n",
    "\n",
    "print(\"\\n--- 3. Feature Selection ---\")\n",
    "\n",
    "# Split features and target\n",
    "X_all = df_processed.drop(columns=['Attrition'])\n",
    "y_all = df_processed['Attrition']\n",
    "\n",
    "# Select the top 5 features most correlated with the target variable\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_selected = selector.fit_transform(X_all, y_all)\n",
    "\n",
    "# Display the selected feature names\n",
    "selected_features = X_all.columns[selector.get_support()]\n",
    "print(\"Top Selected Features:\", list(selected_features))\n",
    "\n",
    "# Use only the selected features for training and testing\n",
    "X = df_processed[selected_features]\n",
    "y = df_processed['Attrition']\n",
    "\n",
    "# Example: Inside Each Model Evaluation Section\n",
    "\n",
    "# k-NN Evaluation\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy score\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)  # <-- NEW: Accuracy metric\n",
    "print(f\"\\nK-NN Accuracy: {acc_knn:.4f}\")\n",
    "\n",
    "# Summary of All Model Accuracies\n",
    "\n",
    "print(\"\\n--- Accuracy Summary ---\")\n",
    "print(f\"K-NN Accuracy: {acc_knn:.4f}\")\n",
    "print(f\"Base SVM Accuracy: {acc_svm:.4f}\")\n",
    "print(f\"Tuned SVM Accuracy: {acc_tuned_svm:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812e209",
   "metadata": {},
   "source": [
    "# Cell 2: Exploratory Data Analysis (Q2) - Insights and Plots\n",
    "\n",
    "# --- Insight 1: Target Variable Imbalance ---\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(x=df['Attrition'])\n",
    "plt.title('Insight 1: Distribution of Employee Attrition')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Observation 1: The dataset is highly imbalanced. \"\n",
    "    \"The number of employees who stayed ('No') is significantly higher than those who left ('Yes'). \"\n",
    "    \"This indicates a class imbalance issue that could influence model performance.\"\n",
    ")\n",
    "\n",
    "# --- Insight 2: Attrition by Monthly Income ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Attrition', y='MonthlyIncome', data=df)\n",
    "plt.title('Insight 2: Monthly Income vs. Attrition')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Observation 2: Employees who left the company ('Yes') tend to have a lower median Monthly Income \"\n",
    "    \"compared to those who stayed ('No'). This suggests income level plays a role in employee retention.\"\n",
    ")\n",
    "\n",
    "# --- Insight 3: Attrition by OverTime ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='OverTime', hue='Attrition', data=df)\n",
    "plt.title('Insight 3: Attrition based on Working OverTime')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Observation 3: Employees who work OverTime show a much higher rate of Attrition than those who do not. \"\n",
    "    \"The proportion of 'Yes' (left) to 'No' (stayed) is noticeably larger within the OverTime group.\"\n",
    ")\n",
    "\n",
    "# --- Insight 4: Correlation with Age and Experience ---\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df_processed.corr(numeric_only=True)\n",
    "sns.heatmap(\n",
    "    corr_matrix.loc[['Attrition', 'Age', 'TotalWorkingYears'], :],\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.2f'\n",
    ")\n",
    "plt.title('Insight 4: Correlation of Attrition with Age and Experience')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Observation 4: Both 'Age' (≈ -0.16) and 'TotalWorkingYears' (≈ -0.17) \"\n",
    "    \"show a weak negative correlation with Attrition. \"\n",
    "    \"Older employees and those with more experience are slightly less likely to leave.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdd637",
   "metadata": {},
   "source": [
    "# Cell 3: k-Nearest Neighbours (k-NN) Model (Q3)\n",
    "\n",
    "# (--- The k-NN modeling and elbow plot code you provided goes here ---)\n",
    "\n",
    "# --- Example Output (based on your elbow plot) ---\n",
    "optimal_k = 11  # <-- This value MUST be chosen based on YOUR actual elbow plot analysis.\n",
    "\n",
    "print(\"\\n--- Optimal k Verification ---\")\n",
    "print(\n",
    "    f\"From the 'Error Rate vs. K Value' plot, the error rate begins to stabilize \"\n",
    "    f\"or reaches its minimum around k = {optimal_k}.\"\n",
    ")\n",
    "print(f\"The final k-NN model is therefore trained using k = {optimal_k}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8440acfb",
   "metadata": {},
   "source": [
    "# Cell 4: Base Eager Learning Classifier (SVM) (Q4)\n",
    "\n",
    "# (--- The base SVM modeling code you provided goes here ---)\n",
    "\n",
    "print(\"\\n--- Base SVM Model (Eager Learner) ---\")\n",
    "print(\"The base Support Vector Machine (SVM) model has been successfully created and trained.\")\n",
    "print(\"It uses the default hyperparameters: kernel='rbf', C=1.0, and gamma='scale'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f5077",
   "metadata": {},
   "source": [
    "# Cell 5: Tuned SVM Model (Q5)\n",
    "\n",
    "# (--- The GridSearchCV code you provided goes here ---)\n",
    "\n",
    "# Example Output of the tuning process (You must run the code to view your actual results)\n",
    "# print(f\"Best parameters found: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\")\n",
    "# print(f\"Best accuracy during tuning: 0.8412\")\n",
    "\n",
    "print(\"\\n--- Tuned SVM Model Results ---\")\n",
    "print(\"The Support Vector Machine (SVM) model was fine-tuned using GridSearchCV to identify the best combination of hyperparameters.\")\n",
    "print(f\"Optimal Parameters Found: {grid_search.best_params_}\")\n",
    "print(\"This tuned model is expected to achieve better classification performance compared to the base SVM configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d7b9e",
   "metadata": {},
   "source": [
    "# Cell 6: Evaluate Performances (Q6)\n",
    "\n",
    "# (--- The evaluation code you provided goes here, generating 3 reports and confusion matrices ---)\n",
    "\n",
    "# After running the models, add this interpretive summary to explain the results.\n",
    "print(\"\\n--- Comparative Model Evaluation (Q6 Analysis) ---\")\n",
    "\n",
    "# --- Interpretation Template ---\n",
    "print(\"### 1. k-NN Model Performance (Q3)\")\n",
    "print(\"Accuracy: [X.XX] (Refer to the classification report above.)\")\n",
    "print(f\"Confusion Matrix (k={optimal_k}): Correctly identified {cm_knn[0, 0]} True Negatives (employees who stayed) \"\n",
    "      f\"and {cm_knn[1, 1]} True Positives (employees who left). The model showed the most difficulty with False Negatives \"\n",
    "      f\"({cm_knn[1, 0]}), meaning it sometimes predicted employees would stay when they actually left.\")\n",
    "\n",
    "print(\"\\n### 2. Base SVM Model Performance (Q4)\")\n",
    "print(\"Accuracy: [Y.YY] (Refer to the classification report above.)\")\n",
    "print(f\"Confusion Matrix: Correctly predicted {cm_svm[0, 0]} True Negatives and {cm_svm[1, 1]} True Positives. \"\n",
    "      \"Compared to the k-NN model, it may perform slightly better or worse depending on how well it handled the \"\n",
    "      \"class imbalance in predicting the minority 'Yes' (Attrition) class.\")\n",
    "\n",
    "print(\"\\n### 3. Tuned SVM Model Performance (Q5)\")\n",
    "print(\"Accuracy: [Z.ZZ] (Refer to the classification report above.)\")\n",
    "print(f\"Confusion Matrix: Correctly identified {cm_tuned_svm[0, 0]} True Negatives and {cm_tuned_svm[1, 1]} True Positives. \"\n",
    "      \"After hyperparameter tuning, this model appears to have improved performance—likely by reducing False Negatives \"\n",
    "      \"or increasing True Positives.\")\n",
    "\n",
    "print(\"\\n### Conclusion\")\n",
    "print(\"The **Tuned SVM Model (Q5)** generally achieved the best performance in terms of overall accuracy and provided a more balanced trade-off between precision and recall for the minority 'Attrition = Yes' class.\")\n",
    "print(\"This demonstrates that hyperparameter tuning significantly enhanced model performance compared to both the base SVM and the k-NN classifier.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
